{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfnIeRPgyk0K",
        "outputId": "4ec49bfc-1f15-47d9-aad6-0a7a7cf934e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load multigraph edges\n",
        "spatial_weights_edges1 = pd.read_csv('/content/drive/MyDrive/London_heat/Connections/spatial_weights_connections.csv')\n",
        "waterway_connections_edges2 = pd.read_csv('/content/drive/MyDrive/London_heat/Connections/waterway_connections.csv')\n",
        "\n",
        "# Load hyperedges (assuming each row represents a hyperedge with nodes separated by commas)\n",
        "LC_hyperedges1 = pd.read_csv('/content/drive/MyDrive/London_heat/Connections/LC_area_connections.csv')\n",
        "LOAC_hyperedges2 = pd.read_csv('/content/drive/MyDrive/London_heat/Connections/LOAC_area_connections.csv')\n",
        "\n",
        "# Load node features and labels\n",
        "nodes = pd.read_csv('/content/drive/MyDrive/London_heat/Connections/data_features_class.csv')\n",
        "\n",
        "# Ensure the column names are correctly mapped\n",
        "spatial_weights_edges1.columns = ['source', 'target']\n",
        "waterway_connections_edges2.columns = ['source', 'target']\n",
        "\n",
        "nodes.columns = ['MSOA_CODE', 'road','sidewalk','building','wall',\t'fence',\t'pole',\t'traffic light',\t'traffic sign',\t'vegetation',\t'terrain',\t'sky',\t'person',\t'rider',\t'car',\t'truck',\t'bus',\t'train',\t'motorcycle',\t'bicycle','subset_vulunability-socio_ZH_VULN_IN_class']\n"
      ],
      "metadata": {
        "id": "DhrMmYGU0jzX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the MultiGraph first"
      ],
      "metadata": {
        "id": "1Ryf9LGR3dEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# Create a MultiGraph\n",
        "G = nx.MultiDiGraph()  # or nx.MultiGraph() for an undirected graph\n",
        "\n",
        "# Add edges from the first CSV\n",
        "for index, row in spatial_weights_edges1.iterrows():\n",
        "    G.add_edge(row['source'], row['target'], key='relation1')\n",
        "\n",
        "# Add edges from the second CSV\n",
        "for index, row in waterway_connections_edges2.iterrows():\n",
        "    G.add_edge(row['source'], row['target'], key='relation2')\n",
        "\n",
        "# Add node features and labels\n",
        "default_features = np.zeros(nodes.shape[1] - 2)  # Default features if a node doesn't have them\n",
        "default_label = -1  # Default label if a node doesn't have it\n",
        "\n",
        "for node in G.nodes():\n",
        "    if node in nodes['MSOA_CODE'].values:\n",
        "        node_data = nodes[nodes['MSOA_CODE'] == node].iloc[0]\n",
        "        G.nodes[node]['features'] = node_data[1:-1].values\n",
        "        G.nodes[node]['label'] = node_data['subset_vulunability-socio_ZH_VULN_IN_class']\n",
        "    else:\n",
        "        G.nodes[node]['features'] = default_features\n",
        "        G.nodes[node]['label'] = default_label\n",
        "\n",
        "# Ensure all nodes have the same attributes\n",
        "for node in G.nodes():\n",
        "    if 'features' not in G.nodes[node]:\n",
        "        G.nodes[node]['features'] = default_features\n",
        "    if 'label' not in G.nodes[node]:\n",
        "        G.nodes[node]['label'] = default_label\n"
      ],
      "metadata": {
        "id": "qUyTGLsg3bxq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypergraph"
      ],
      "metadata": {
        "id": "4agayRXI48l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode node IDs to integers\n",
        "le = LabelEncoder()\n",
        "all_nodes = pd.concat([nodes['MSOA_CODE'], LC_hyperedges1['source'], LC_hyperedges1['target'], LOAC_hyperedges2['source'], LOAC_hyperedges2['target']])\n",
        "le.fit(all_nodes)\n",
        "\n",
        "nodes['MSOA_CODE'] = le.transform(nodes['MSOA_CODE'])\n",
        "LC_hyperedges1['source'] = le.transform(LC_hyperedges1['source'])\n",
        "LC_hyperedges1['target'] = le.transform(LC_hyperedges1['target'])\n",
        "LOAC_hyperedges2['source'] = le.transform(LOAC_hyperedges2['source'])\n",
        "LOAC_hyperedges2['target'] = le.transform(LOAC_hyperedges2['target'])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def create_hyperedge_incidence_matrix(edges, num_nodes):\n",
        "    hyperedge_dict = {}\n",
        "    for _, row in edges.iterrows():\n",
        "        if row['target'] not in hyperedge_dict:\n",
        "            hyperedge_dict[row['target']] = []\n",
        "        hyperedge_dict[row['target']].append(row['source'])\n",
        "\n",
        "    num_hyperedges = len(hyperedge_dict)\n",
        "    incidence_matrix = np.zeros((num_nodes, num_hyperedges))\n",
        "\n",
        "    for col, nodes in enumerate(hyperedge_dict.values()):\n",
        "        for node in nodes:\n",
        "            incidence_matrix[node, col] = 1\n",
        "\n",
        "    return incidence_matrix\n",
        "\n",
        "num_nodes = nodes.shape[0]\n",
        "incidence_matrix1 = create_hyperedge_incidence_matrix(LC_hyperedges1, num_nodes)\n",
        "incidence_matrix2 = create_hyperedge_incidence_matrix(LOAC_hyperedges2, num_nodes)\n"
      ],
      "metadata": {
        "id": "6_BSTzNa4eu5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "# Convert the NetworkX multigraph to PyTorch Geometric format\n",
        "multigraph_data = from_networkx(G)\n",
        "\n",
        "\n",
        "\n",
        "def incidence_matrix_to_hyperedge_index(incidence_matrix):\n",
        "    rows, cols = np.nonzero(incidence_matrix)\n",
        "    edge_index = np.vstack((rows, cols))\n",
        "    return edge_index\n",
        "\n",
        "# Convert incidence matrices to hyperedge indices\n",
        "hyperedge_index1 = incidence_matrix_to_hyperedge_index(incidence_matrix1)\n",
        "hyperedge_index2 = incidence_matrix_to_hyperedge_index(incidence_matrix2)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "hyperedge_index1 = torch.tensor(hyperedge_index1, dtype=torch.long)\n",
        "hyperedge_index2 = torch.tensor(hyperedge_index2, dtype=torch.long)\n",
        "\n",
        "# Verify shapes\n",
        "print(hyperedge_index1.shape)  # Should be (2, num_edges1)\n",
        "print(hyperedge_index2.shape)  # Should be (2, num_edges2)\n",
        "\n",
        "# Extract node features and labels\n",
        "node_features = torch.tensor(nodes.iloc[:, 1:-1].values, dtype=torch.float)\n",
        "node_labels = torch.tensor(nodes['subset_vulunability-socio_ZH_VULN_IN_class'].values, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch Geometric data object\n",
        "data = Data(x=node_features, y=node_labels)\n",
        "data.hyperedge_index1 = hyperedge_index1.to(torch.long)\n",
        "data.hyperedge_index2 = hyperedge_index2.to(torch.long)\n",
        "data.edge_index = multigraph_data.edge_index\n",
        "data.edge_index = data.edge_index.clamp(0, data.num_nodes - 1)\n",
        "\n",
        "data.edge_attr = multigraph_data.edge_attr\n",
        "\n",
        "# Split the dataset\n",
        "train_mask, test_mask = train_test_split(range(data.num_nodes), test_size=0.2, stratify=data.y)\n",
        "train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
        "test_mask = torch.tensor(test_mask, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aA_jvTN9x-p",
        "outputId": "411bd662-32a3-4edd-949d-a6138a02935f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 388454])\n",
            "torch.Size([2, 41997])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(logits, labels, mask):\n",
        "    _, preds = torch.max(logits[mask], dim=1)\n",
        "    correct = (preds == labels[mask]).sum().item()\n",
        "    total = mask.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "4a6jP_2JCm5O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, HypergraphConv\n",
        "\n",
        "class CombinedGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(CombinedGNN, self).__init__()\n",
        "        self.gcn1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.hyperconv1 = HypergraphConv(input_dim, hidden_dim)\n",
        "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.hyperconv2 = HypergraphConv(hidden_dim, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # GCN part\n",
        "        x_gcn = self.gcn1(data.x, data.edge_index)\n",
        "        x_gcn = F.relu(x_gcn)\n",
        "        x_gcn = self.gcn2(x_gcn, data.edge_index)\n",
        "\n",
        "        # Hypergraph part\n",
        "        x_hyper1 = self.hyperconv1(data.x, data.hyperedge_index1)\n",
        "        x_hyper1 = F.relu(x_hyper1)\n",
        "        x_hyper2 = self.hyperconv2(x_hyper1, data.hyperedge_index2)\n",
        "\n",
        "        # Combine features from both parts\n",
        "        x = torch.cat([x_gcn, x_hyper2], dim=1)\n",
        "\n",
        "        # Final classification\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "input_dim = node_features.shape[1]\n",
        "hidden_dim = 16\n",
        "output_dim = 3  # Assuming labels are integers starting from 0\n",
        "\n",
        "model = CombinedGNN(input_dim, hidden_dim, output_dim)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), out\n",
        "\n",
        "best_train_acc = 0\n",
        "best_epoch = 0\n",
        "best_model_state = None\n",
        "patience = 50\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(5000):\n",
        "    loss, train_out = train()\n",
        "    train_acc = compute_accuracy(train_out, data.y, train_mask)\n",
        "    print(f\"Epoch {epoch + 1}: Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "    # Check for best train accuracy\n",
        "    if train_acc > best_train_acc:\n",
        "        best_train_acc = train_acc\n",
        "        best_epoch = epoch\n",
        "        best_model_state = model.state_dict()\n",
        "        counter = 0  # Reset patience counter\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Stop if patience is exceeded\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping at epoch\", epoch + 1)\n",
        "        break\n",
        "\n",
        "# Load the best model state\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Evaluate on the test set using the best model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_out = model(data)\n",
        "    final_test_acc = compute_accuracy(test_out, data.y, test_mask)\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}, Train Accuracy: {best_train_acc:.4f}\")\n",
        "print(\"Final Test Accuracy:\", final_test_acc)\n"
      ],
      "metadata": {
        "id": "143sbRbwyoVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7818cd-9ee7-4e06-aee1-d4f28a421ec8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 1.0984, Train Accuracy: 0.4714\n",
            "Epoch 2/500, Loss: 1.0606, Train Accuracy: 0.4714\n",
            "Epoch 3/500, Loss: 1.0483, Train Accuracy: 0.4714\n",
            "Epoch 4/500, Loss: 1.0517, Train Accuracy: 0.4714\n",
            "Epoch 5/500, Loss: 1.0537, Train Accuracy: 0.4714\n",
            "Epoch 6/500, Loss: 1.0492, Train Accuracy: 0.4714\n",
            "Epoch 7/500, Loss: 1.0419, Train Accuracy: 0.4714\n",
            "Epoch 8/500, Loss: 1.0352, Train Accuracy: 0.4714\n",
            "Epoch 9/500, Loss: 1.0302, Train Accuracy: 0.4714\n",
            "Epoch 10/500, Loss: 1.0266, Train Accuracy: 0.4857\n",
            "Epoch 11/500, Loss: 1.0236, Train Accuracy: 0.5000\n",
            "Epoch 12/500, Loss: 1.0198, Train Accuracy: 0.5000\n",
            "Epoch 13/500, Loss: 1.0145, Train Accuracy: 0.5000\n",
            "Epoch 14/500, Loss: 1.0083, Train Accuracy: 0.5143\n",
            "Epoch 15/500, Loss: 1.0019, Train Accuracy: 0.5143\n",
            "Epoch 16/500, Loss: 0.9956, Train Accuracy: 0.5286\n",
            "Epoch 17/500, Loss: 0.9893, Train Accuracy: 0.5571\n",
            "Epoch 18/500, Loss: 0.9834, Train Accuracy: 0.5571\n",
            "Epoch 19/500, Loss: 0.9779, Train Accuracy: 0.5429\n",
            "Epoch 20/500, Loss: 0.9725, Train Accuracy: 0.5286\n",
            "Epoch 21/500, Loss: 0.9671, Train Accuracy: 0.5000\n",
            "Epoch 22/500, Loss: 0.9616, Train Accuracy: 0.5000\n",
            "Epoch 23/500, Loss: 0.9561, Train Accuracy: 0.5000\n",
            "Epoch 24/500, Loss: 0.9504, Train Accuracy: 0.4857\n",
            "Epoch 25/500, Loss: 0.9448, Train Accuracy: 0.5000\n",
            "Epoch 26/500, Loss: 0.9394, Train Accuracy: 0.5143\n",
            "Epoch 27/500, Loss: 0.9343, Train Accuracy: 0.5143\n",
            "Epoch 28/500, Loss: 0.9290, Train Accuracy: 0.5286\n",
            "Epoch 29/500, Loss: 0.9228, Train Accuracy: 0.5429\n",
            "Epoch 30/500, Loss: 0.9164, Train Accuracy: 0.5571\n",
            "Epoch 31/500, Loss: 0.9096, Train Accuracy: 0.5571\n",
            "Epoch 32/500, Loss: 0.9024, Train Accuracy: 0.5429\n",
            "Epoch 33/500, Loss: 0.8954, Train Accuracy: 0.5571\n",
            "Epoch 34/500, Loss: 0.8883, Train Accuracy: 0.5714\n",
            "Epoch 35/500, Loss: 0.8813, Train Accuracy: 0.6000\n",
            "Epoch 36/500, Loss: 0.8748, Train Accuracy: 0.6000\n",
            "Epoch 37/500, Loss: 0.8684, Train Accuracy: 0.5857\n",
            "Epoch 38/500, Loss: 0.8624, Train Accuracy: 0.5714\n",
            "Epoch 39/500, Loss: 0.8571, Train Accuracy: 0.5714\n",
            "Epoch 40/500, Loss: 0.8524, Train Accuracy: 0.6000\n",
            "Epoch 41/500, Loss: 0.8494, Train Accuracy: 0.5571\n",
            "Epoch 42/500, Loss: 0.8448, Train Accuracy: 0.5714\n",
            "Epoch 43/500, Loss: 0.8387, Train Accuracy: 0.6143\n",
            "Epoch 44/500, Loss: 0.8362, Train Accuracy: 0.5714\n",
            "Epoch 45/500, Loss: 0.8322, Train Accuracy: 0.5857\n",
            "Epoch 46/500, Loss: 0.8265, Train Accuracy: 0.6000\n",
            "Epoch 47/500, Loss: 0.8235, Train Accuracy: 0.5857\n",
            "Epoch 48/500, Loss: 0.8187, Train Accuracy: 0.5714\n",
            "Epoch 49/500, Loss: 0.8141, Train Accuracy: 0.6000\n",
            "Epoch 50/500, Loss: 0.8101, Train Accuracy: 0.5857\n",
            "Epoch 51/500, Loss: 0.8051, Train Accuracy: 0.5857\n",
            "Epoch 52/500, Loss: 0.8008, Train Accuracy: 0.6429\n",
            "Epoch 53/500, Loss: 0.7968, Train Accuracy: 0.6143\n",
            "Epoch 54/500, Loss: 0.7919, Train Accuracy: 0.6143\n",
            "Epoch 55/500, Loss: 0.7882, Train Accuracy: 0.6286\n",
            "Epoch 56/500, Loss: 0.7846, Train Accuracy: 0.6143\n",
            "Epoch 57/500, Loss: 0.7800, Train Accuracy: 0.6286\n",
            "Epoch 58/500, Loss: 0.7755, Train Accuracy: 0.6286\n",
            "Epoch 59/500, Loss: 0.7718, Train Accuracy: 0.6286\n",
            "Epoch 60/500, Loss: 0.7679, Train Accuracy: 0.6286\n",
            "Epoch 61/500, Loss: 0.7633, Train Accuracy: 0.6571\n",
            "Epoch 62/500, Loss: 0.7585, Train Accuracy: 0.6571\n",
            "Epoch 63/500, Loss: 0.7539, Train Accuracy: 0.6714\n",
            "Epoch 64/500, Loss: 0.7497, Train Accuracy: 0.6714\n",
            "Epoch 65/500, Loss: 0.7461, Train Accuracy: 0.6571\n",
            "Epoch 66/500, Loss: 0.7419, Train Accuracy: 0.6714\n",
            "Epoch 67/500, Loss: 0.7369, Train Accuracy: 0.6857\n",
            "Epoch 68/500, Loss: 0.7322, Train Accuracy: 0.6714\n",
            "Epoch 69/500, Loss: 0.7273, Train Accuracy: 0.6857\n",
            "Epoch 70/500, Loss: 0.7231, Train Accuracy: 0.6571\n",
            "Epoch 71/500, Loss: 0.7202, Train Accuracy: 0.6571\n",
            "Epoch 72/500, Loss: 0.7160, Train Accuracy: 0.6571\n",
            "Epoch 73/500, Loss: 0.7119, Train Accuracy: 0.6714\n",
            "Epoch 74/500, Loss: 0.7068, Train Accuracy: 0.6571\n",
            "Epoch 75/500, Loss: 0.7009, Train Accuracy: 0.6714\n",
            "Epoch 76/500, Loss: 0.6971, Train Accuracy: 0.6714\n",
            "Epoch 77/500, Loss: 0.6955, Train Accuracy: 0.6571\n",
            "Epoch 78/500, Loss: 0.6933, Train Accuracy: 0.7000\n",
            "Epoch 79/500, Loss: 0.6889, Train Accuracy: 0.6714\n",
            "Epoch 80/500, Loss: 0.6819, Train Accuracy: 0.6714\n",
            "Epoch 81/500, Loss: 0.6780, Train Accuracy: 0.6857\n",
            "Epoch 82/500, Loss: 0.6770, Train Accuracy: 0.6571\n",
            "Epoch 83/500, Loss: 0.6734, Train Accuracy: 0.6857\n",
            "Epoch 84/500, Loss: 0.6678, Train Accuracy: 0.6857\n",
            "Epoch 85/500, Loss: 0.6631, Train Accuracy: 0.6714\n",
            "Epoch 86/500, Loss: 0.6610, Train Accuracy: 0.7000\n",
            "Epoch 87/500, Loss: 0.6589, Train Accuracy: 0.6714\n",
            "Epoch 88/500, Loss: 0.6544, Train Accuracy: 0.7000\n",
            "Epoch 89/500, Loss: 0.6495, Train Accuracy: 0.6857\n",
            "Epoch 90/500, Loss: 0.6461, Train Accuracy: 0.6857\n",
            "Epoch 91/500, Loss: 0.6436, Train Accuracy: 0.7000\n",
            "Epoch 92/500, Loss: 0.6416, Train Accuracy: 0.6857\n",
            "Epoch 93/500, Loss: 0.6385, Train Accuracy: 0.7000\n",
            "Epoch 94/500, Loss: 0.6348, Train Accuracy: 0.7000\n",
            "Epoch 95/500, Loss: 0.6311, Train Accuracy: 0.7143\n",
            "Epoch 96/500, Loss: 0.6274, Train Accuracy: 0.7000\n",
            "Epoch 97/500, Loss: 0.6235, Train Accuracy: 0.7286\n",
            "Epoch 98/500, Loss: 0.6202, Train Accuracy: 0.7286\n",
            "Epoch 99/500, Loss: 0.6170, Train Accuracy: 0.7286\n",
            "Epoch 100/500, Loss: 0.6138, Train Accuracy: 0.7143\n",
            "Epoch 101/500, Loss: 0.6108, Train Accuracy: 0.7143\n",
            "Epoch 102/500, Loss: 0.6076, Train Accuracy: 0.7143\n",
            "Epoch 103/500, Loss: 0.6046, Train Accuracy: 0.7143\n",
            "Epoch 104/500, Loss: 0.6011, Train Accuracy: 0.7286\n",
            "Epoch 105/500, Loss: 0.5980, Train Accuracy: 0.7000\n",
            "Epoch 106/500, Loss: 0.5952, Train Accuracy: 0.7429\n",
            "Epoch 107/500, Loss: 0.5958, Train Accuracy: 0.6857\n",
            "Epoch 108/500, Loss: 0.6119, Train Accuracy: 0.7143\n",
            "Epoch 109/500, Loss: 0.6422, Train Accuracy: 0.6857\n",
            "Epoch 110/500, Loss: 0.6013, Train Accuracy: 0.6857\n",
            "Epoch 111/500, Loss: 0.5934, Train Accuracy: 0.7429\n",
            "Epoch 112/500, Loss: 0.6081, Train Accuracy: 0.7571\n",
            "Epoch 113/500, Loss: 0.5791, Train Accuracy: 0.6857\n",
            "Epoch 114/500, Loss: 0.6018, Train Accuracy: 0.7429\n",
            "Epoch 115/500, Loss: 0.5740, Train Accuracy: 0.7286\n",
            "Epoch 116/500, Loss: 0.5915, Train Accuracy: 0.7000\n",
            "Epoch 117/500, Loss: 0.5690, Train Accuracy: 0.6857\n",
            "Epoch 118/500, Loss: 0.5840, Train Accuracy: 0.7714\n",
            "Epoch 119/500, Loss: 0.5704, Train Accuracy: 0.7571\n",
            "Epoch 120/500, Loss: 0.5686, Train Accuracy: 0.7000\n",
            "Epoch 121/500, Loss: 0.5678, Train Accuracy: 0.6857\n",
            "Epoch 122/500, Loss: 0.5602, Train Accuracy: 0.7714\n",
            "Epoch 123/500, Loss: 0.5628, Train Accuracy: 0.7857\n",
            "Epoch 124/500, Loss: 0.5532, Train Accuracy: 0.6857\n",
            "Epoch 125/500, Loss: 0.5564, Train Accuracy: 0.7571\n",
            "Epoch 126/500, Loss: 0.5462, Train Accuracy: 0.7714\n",
            "Epoch 127/500, Loss: 0.5514, Train Accuracy: 0.7714\n",
            "Epoch 128/500, Loss: 0.5405, Train Accuracy: 0.7143\n",
            "Epoch 129/500, Loss: 0.5459, Train Accuracy: 0.7714\n",
            "Epoch 130/500, Loss: 0.5357, Train Accuracy: 0.7714\n",
            "Epoch 131/500, Loss: 0.5379, Train Accuracy: 0.7286\n",
            "Epoch 132/500, Loss: 0.5327, Train Accuracy: 0.7286\n",
            "Epoch 133/500, Loss: 0.5322, Train Accuracy: 0.8143\n",
            "Epoch 134/500, Loss: 0.5294, Train Accuracy: 0.8143\n",
            "Epoch 135/500, Loss: 0.5256, Train Accuracy: 0.7429\n",
            "Epoch 136/500, Loss: 0.5244, Train Accuracy: 0.7857\n",
            "Epoch 137/500, Loss: 0.5193, Train Accuracy: 0.8000\n",
            "Epoch 138/500, Loss: 0.5206, Train Accuracy: 0.7714\n",
            "Epoch 139/500, Loss: 0.5158, Train Accuracy: 0.8000\n",
            "Epoch 140/500, Loss: 0.5144, Train Accuracy: 0.8000\n",
            "Epoch 141/500, Loss: 0.5121, Train Accuracy: 0.7714\n",
            "Epoch 142/500, Loss: 0.5088, Train Accuracy: 0.7714\n",
            "Epoch 143/500, Loss: 0.5084, Train Accuracy: 0.8143\n",
            "Epoch 144/500, Loss: 0.5055, Train Accuracy: 0.8286\n",
            "Epoch 145/500, Loss: 0.5041, Train Accuracy: 0.8143\n",
            "Epoch 146/500, Loss: 0.5025, Train Accuracy: 0.8143\n",
            "Epoch 147/500, Loss: 0.4998, Train Accuracy: 0.8286\n",
            "Epoch 148/500, Loss: 0.4988, Train Accuracy: 0.8143\n",
            "Epoch 149/500, Loss: 0.4968, Train Accuracy: 0.8286\n",
            "Epoch 150/500, Loss: 0.4945, Train Accuracy: 0.8429\n",
            "Epoch 151/500, Loss: 0.4936, Train Accuracy: 0.8143\n",
            "Epoch 152/500, Loss: 0.4917, Train Accuracy: 0.8429\n",
            "Epoch 153/500, Loss: 0.4896, Train Accuracy: 0.8286\n",
            "Epoch 154/500, Loss: 0.4888, Train Accuracy: 0.8143\n",
            "Epoch 155/500, Loss: 0.4871, Train Accuracy: 0.8429\n",
            "Epoch 156/500, Loss: 0.4849, Train Accuracy: 0.8571\n",
            "Epoch 157/500, Loss: 0.4834, Train Accuracy: 0.8143\n",
            "Epoch 158/500, Loss: 0.4824, Train Accuracy: 0.8429\n",
            "Epoch 159/500, Loss: 0.4807, Train Accuracy: 0.8429\n",
            "Epoch 160/500, Loss: 0.4788, Train Accuracy: 0.8286\n",
            "Epoch 161/500, Loss: 0.4774, Train Accuracy: 0.8571\n",
            "Epoch 162/500, Loss: 0.4764, Train Accuracy: 0.8143\n",
            "Epoch 163/500, Loss: 0.4749, Train Accuracy: 0.8571\n",
            "Epoch 164/500, Loss: 0.4732, Train Accuracy: 0.8286\n",
            "Epoch 165/500, Loss: 0.4715, Train Accuracy: 0.8429\n",
            "Epoch 166/500, Loss: 0.4700, Train Accuracy: 0.8571\n",
            "Epoch 167/500, Loss: 0.4686, Train Accuracy: 0.8286\n",
            "Epoch 168/500, Loss: 0.4673, Train Accuracy: 0.8571\n",
            "Epoch 169/500, Loss: 0.4660, Train Accuracy: 0.8143\n",
            "Epoch 170/500, Loss: 0.4646, Train Accuracy: 0.8571\n",
            "Epoch 171/500, Loss: 0.4630, Train Accuracy: 0.8286\n",
            "Epoch 172/500, Loss: 0.4617, Train Accuracy: 0.8571\n",
            "Epoch 173/500, Loss: 0.4603, Train Accuracy: 0.8286\n",
            "Epoch 174/500, Loss: 0.4588, Train Accuracy: 0.8571\n",
            "Epoch 175/500, Loss: 0.4574, Train Accuracy: 0.8143\n",
            "Epoch 176/500, Loss: 0.4562, Train Accuracy: 0.8571\n",
            "Epoch 177/500, Loss: 0.4553, Train Accuracy: 0.8000\n",
            "Epoch 178/500, Loss: 0.4558, Train Accuracy: 0.8571\n",
            "Epoch 179/500, Loss: 0.4588, Train Accuracy: 0.7429\n",
            "Epoch 180/500, Loss: 0.4670, Train Accuracy: 0.8143\n",
            "Epoch 181/500, Loss: 0.4749, Train Accuracy: 0.7429\n",
            "Epoch 182/500, Loss: 0.4720, Train Accuracy: 0.8571\n",
            "Epoch 183/500, Loss: 0.4524, Train Accuracy: 0.8571\n",
            "Epoch 184/500, Loss: 0.4474, Train Accuracy: 0.7429\n",
            "Epoch 185/500, Loss: 0.4589, Train Accuracy: 0.8286\n",
            "Epoch 186/500, Loss: 0.4555, Train Accuracy: 0.8000\n",
            "Epoch 187/500, Loss: 0.4436, Train Accuracy: 0.8000\n",
            "Epoch 188/500, Loss: 0.4440, Train Accuracy: 0.8429\n",
            "Epoch 189/500, Loss: 0.4501, Train Accuracy: 0.7714\n",
            "Epoch 190/500, Loss: 0.4462, Train Accuracy: 0.8571\n",
            "Epoch 191/500, Loss: 0.4383, Train Accuracy: 0.8571\n",
            "Epoch 192/500, Loss: 0.4401, Train Accuracy: 0.7714\n",
            "Epoch 193/500, Loss: 0.4436, Train Accuracy: 0.8571\n",
            "Epoch 194/500, Loss: 0.4379, Train Accuracy: 0.8429\n",
            "Epoch 195/500, Loss: 0.4336, Train Accuracy: 0.8000\n",
            "Epoch 196/500, Loss: 0.4356, Train Accuracy: 0.8571\n",
            "Epoch 197/500, Loss: 0.4369, Train Accuracy: 0.8000\n",
            "Epoch 198/500, Loss: 0.4334, Train Accuracy: 0.8571\n",
            "Epoch 199/500, Loss: 0.4294, Train Accuracy: 0.8571\n",
            "Epoch 200/500, Loss: 0.4297, Train Accuracy: 0.7857\n",
            "Epoch 201/500, Loss: 0.4309, Train Accuracy: 0.8571\n",
            "Epoch 202/500, Loss: 0.4287, Train Accuracy: 0.8429\n",
            "Epoch 203/500, Loss: 0.4255, Train Accuracy: 0.8429\n",
            "Epoch 204/500, Loss: 0.4246, Train Accuracy: 0.8571\n",
            "Epoch 205/500, Loss: 0.4257, Train Accuracy: 0.7857\n",
            "Epoch 206/500, Loss: 0.4257, Train Accuracy: 0.8571\n",
            "Epoch 207/500, Loss: 0.4232, Train Accuracy: 0.8429\n",
            "Epoch 208/500, Loss: 0.4203, Train Accuracy: 0.8429\n",
            "Epoch 209/500, Loss: 0.4193, Train Accuracy: 0.8571\n",
            "Epoch 210/500, Loss: 0.4199, Train Accuracy: 0.8000\n",
            "Epoch 211/500, Loss: 0.4202, Train Accuracy: 0.8571\n",
            "Epoch 212/500, Loss: 0.4193, Train Accuracy: 0.7857\n",
            "Epoch 213/500, Loss: 0.4174, Train Accuracy: 0.8571\n",
            "Epoch 214/500, Loss: 0.4150, Train Accuracy: 0.8429\n",
            "Epoch 215/500, Loss: 0.4132, Train Accuracy: 0.8286\n",
            "Epoch 216/500, Loss: 0.4127, Train Accuracy: 0.8571\n",
            "Epoch 217/500, Loss: 0.4130, Train Accuracy: 0.7857\n",
            "Epoch 218/500, Loss: 0.4136, Train Accuracy: 0.8714\n",
            "Epoch 219/500, Loss: 0.4147, Train Accuracy: 0.7714\n",
            "Epoch 220/500, Loss: 0.4146, Train Accuracy: 0.8714\n",
            "Epoch 221/500, Loss: 0.4126, Train Accuracy: 0.7857\n",
            "Epoch 222/500, Loss: 0.4096, Train Accuracy: 0.8571\n",
            "Epoch 223/500, Loss: 0.4068, Train Accuracy: 0.8286\n",
            "Epoch 224/500, Loss: 0.4050, Train Accuracy: 0.8143\n",
            "Epoch 225/500, Loss: 0.4044, Train Accuracy: 0.8714\n",
            "Epoch 226/500, Loss: 0.4043, Train Accuracy: 0.7857\n",
            "Epoch 227/500, Loss: 0.4041, Train Accuracy: 0.8714\n",
            "Epoch 228/500, Loss: 0.4036, Train Accuracy: 0.8000\n",
            "Epoch 229/500, Loss: 0.4029, Train Accuracy: 0.8857\n",
            "Epoch 230/500, Loss: 0.4029, Train Accuracy: 0.7857\n",
            "Epoch 231/500, Loss: 0.4035, Train Accuracy: 0.8857\n",
            "Epoch 232/500, Loss: 0.4047, Train Accuracy: 0.7714\n",
            "Epoch 233/500, Loss: 0.4062, Train Accuracy: 0.8857\n",
            "Epoch 234/500, Loss: 0.4080, Train Accuracy: 0.7571\n",
            "Epoch 235/500, Loss: 0.4078, Train Accuracy: 0.8857\n",
            "Epoch 236/500, Loss: 0.4047, Train Accuracy: 0.7857\n",
            "Epoch 237/500, Loss: 0.3998, Train Accuracy: 0.8857\n",
            "Epoch 238/500, Loss: 0.3953, Train Accuracy: 0.8143\n",
            "Epoch 239/500, Loss: 0.3924, Train Accuracy: 0.8143\n",
            "Epoch 240/500, Loss: 0.3918, Train Accuracy: 0.8857\n",
            "Epoch 241/500, Loss: 0.3925, Train Accuracy: 0.7857\n",
            "Epoch 242/500, Loss: 0.3939, Train Accuracy: 0.9000\n",
            "Epoch 243/500, Loss: 0.3945, Train Accuracy: 0.7857\n",
            "Epoch 244/500, Loss: 0.3945, Train Accuracy: 0.9000\n",
            "Epoch 245/500, Loss: 0.3929, Train Accuracy: 0.7857\n",
            "Epoch 246/500, Loss: 0.3907, Train Accuracy: 0.8857\n",
            "Epoch 247/500, Loss: 0.3884, Train Accuracy: 0.8143\n",
            "Epoch 248/500, Loss: 0.3863, Train Accuracy: 0.8429\n",
            "Epoch 249/500, Loss: 0.3847, Train Accuracy: 0.8286\n",
            "Epoch 250/500, Loss: 0.3837, Train Accuracy: 0.8286\n",
            "Epoch 251/500, Loss: 0.3832, Train Accuracy: 0.8857\n",
            "Epoch 252/500, Loss: 0.3831, Train Accuracy: 0.8143\n",
            "Epoch 253/500, Loss: 0.3841, Train Accuracy: 0.8857\n",
            "Epoch 254/500, Loss: 0.3845, Train Accuracy: 0.8000\n",
            "Epoch 255/500, Loss: 0.3841, Train Accuracy: 0.8857\n",
            "Epoch 256/500, Loss: 0.3850, Train Accuracy: 0.7857\n",
            "Epoch 257/500, Loss: 0.3864, Train Accuracy: 0.8857\n",
            "Epoch 258/500, Loss: 0.3879, Train Accuracy: 0.7857\n",
            "Epoch 259/500, Loss: 0.3884, Train Accuracy: 0.8857\n",
            "Epoch 260/500, Loss: 0.3870, Train Accuracy: 0.7857\n",
            "Epoch 261/500, Loss: 0.3834, Train Accuracy: 0.8857\n",
            "Epoch 262/500, Loss: 0.3785, Train Accuracy: 0.8429\n",
            "Epoch 263/500, Loss: 0.3752, Train Accuracy: 0.8571\n",
            "Epoch 264/500, Loss: 0.3737, Train Accuracy: 0.8857\n",
            "Epoch 265/500, Loss: 0.3740, Train Accuracy: 0.7857\n",
            "Epoch 266/500, Loss: 0.3761, Train Accuracy: 0.8857\n",
            "Epoch 267/500, Loss: 0.3805, Train Accuracy: 0.7714\n",
            "Epoch 268/500, Loss: 0.3836, Train Accuracy: 0.8857\n",
            "Epoch 269/500, Loss: 0.3839, Train Accuracy: 0.7714\n",
            "Epoch 270/500, Loss: 0.3798, Train Accuracy: 0.8857\n",
            "Epoch 271/500, Loss: 0.3741, Train Accuracy: 0.8571\n",
            "Epoch 272/500, Loss: 0.3690, Train Accuracy: 0.8571\n",
            "Epoch 273/500, Loss: 0.3673, Train Accuracy: 0.8857\n",
            "Epoch 274/500, Loss: 0.3687, Train Accuracy: 0.7857\n",
            "Epoch 275/500, Loss: 0.3718, Train Accuracy: 0.8857\n",
            "Epoch 276/500, Loss: 0.3740, Train Accuracy: 0.7857\n",
            "Epoch 277/500, Loss: 0.3732, Train Accuracy: 0.8714\n",
            "Epoch 278/500, Loss: 0.3695, Train Accuracy: 0.8571\n",
            "Epoch 279/500, Loss: 0.3648, Train Accuracy: 0.8571\n",
            "Epoch 280/500, Loss: 0.3624, Train Accuracy: 0.8714\n",
            "Epoch 281/500, Loss: 0.3631, Train Accuracy: 0.8429\n",
            "Epoch 282/500, Loss: 0.3640, Train Accuracy: 0.8714\n",
            "Epoch 283/500, Loss: 0.3635, Train Accuracy: 0.8571\n",
            "Epoch 284/500, Loss: 0.3624, Train Accuracy: 0.8714\n",
            "Epoch 285/500, Loss: 0.3620, Train Accuracy: 0.8571\n",
            "Epoch 286/500, Loss: 0.3607, Train Accuracy: 0.8571\n",
            "Epoch 287/500, Loss: 0.3596, Train Accuracy: 0.8571\n",
            "Epoch 288/500, Loss: 0.3581, Train Accuracy: 0.8571\n",
            "Epoch 289/500, Loss: 0.3566, Train Accuracy: 0.8571\n",
            "Epoch 290/500, Loss: 0.3559, Train Accuracy: 0.8571\n",
            "Epoch 291/500, Loss: 0.3552, Train Accuracy: 0.8571\n",
            "Epoch 292/500, Loss: 0.3548, Train Accuracy: 0.8571\n",
            "Epoch 293/500, Loss: 0.3547, Train Accuracy: 0.8714\n",
            "Epoch 294/500, Loss: 0.3564, Train Accuracy: 0.8000\n",
            "Epoch 295/500, Loss: 0.3605, Train Accuracy: 0.8857\n",
            "Epoch 296/500, Loss: 0.3692, Train Accuracy: 0.7714\n",
            "Epoch 297/500, Loss: 0.3847, Train Accuracy: 0.8714\n",
            "Epoch 298/500, Loss: 0.3961, Train Accuracy: 0.7857\n",
            "Epoch 299/500, Loss: 0.3866, Train Accuracy: 0.8714\n",
            "Epoch 300/500, Loss: 0.3568, Train Accuracy: 0.8714\n",
            "Epoch 301/500, Loss: 0.3557, Train Accuracy: 0.7714\n",
            "Epoch 302/500, Loss: 0.3783, Train Accuracy: 0.8714\n",
            "Epoch 303/500, Loss: 0.3780, Train Accuracy: 0.8000\n",
            "Epoch 304/500, Loss: 0.3595, Train Accuracy: 0.8571\n",
            "Epoch 305/500, Loss: 0.3470, Train Accuracy: 0.8857\n",
            "Epoch 306/500, Loss: 0.3563, Train Accuracy: 0.7714\n",
            "Epoch 307/500, Loss: 0.3647, Train Accuracy: 0.8857\n",
            "Epoch 308/500, Loss: 0.3545, Train Accuracy: 0.8571\n",
            "Epoch 309/500, Loss: 0.3451, Train Accuracy: 0.8143\n",
            "Epoch 310/500, Loss: 0.3531, Train Accuracy: 0.8857\n",
            "Epoch 311/500, Loss: 0.3614, Train Accuracy: 0.8286\n",
            "Epoch 312/500, Loss: 0.3553, Train Accuracy: 0.8571\n",
            "Epoch 313/500, Loss: 0.3437, Train Accuracy: 0.8571\n",
            "Epoch 314/500, Loss: 0.3452, Train Accuracy: 0.8143\n",
            "Epoch 315/500, Loss: 0.3521, Train Accuracy: 0.8857\n",
            "Epoch 316/500, Loss: 0.3502, Train Accuracy: 0.8571\n",
            "Epoch 317/500, Loss: 0.3418, Train Accuracy: 0.8571\n",
            "Epoch 318/500, Loss: 0.3415, Train Accuracy: 0.8714\n",
            "Epoch 319/500, Loss: 0.3471, Train Accuracy: 0.8286\n",
            "Epoch 320/500, Loss: 0.3487, Train Accuracy: 0.8571\n",
            "Epoch 321/500, Loss: 0.3427, Train Accuracy: 0.8571\n",
            "Epoch 322/500, Loss: 0.3381, Train Accuracy: 0.8571\n",
            "Epoch 323/500, Loss: 0.3384, Train Accuracy: 0.8714\n",
            "Epoch 324/500, Loss: 0.3406, Train Accuracy: 0.8571\n",
            "Epoch 325/500, Loss: 0.3400, Train Accuracy: 0.8429\n",
            "Epoch 326/500, Loss: 0.3362, Train Accuracy: 0.8429\n",
            "Epoch 327/500, Loss: 0.3347, Train Accuracy: 0.8571\n",
            "Epoch 328/500, Loss: 0.3365, Train Accuracy: 0.8714\n",
            "Epoch 329/500, Loss: 0.3391, Train Accuracy: 0.8286\n",
            "Epoch 330/500, Loss: 0.3397, Train Accuracy: 0.8714\n",
            "Epoch 331/500, Loss: 0.3364, Train Accuracy: 0.8571\n",
            "Epoch 332/500, Loss: 0.3334, Train Accuracy: 0.8571\n",
            "Epoch 333/500, Loss: 0.3317, Train Accuracy: 0.8714\n",
            "Epoch 334/500, Loss: 0.3323, Train Accuracy: 0.8571\n",
            "Epoch 335/500, Loss: 0.3330, Train Accuracy: 0.8714\n",
            "Epoch 336/500, Loss: 0.3333, Train Accuracy: 0.8571\n",
            "Epoch 337/500, Loss: 0.3320, Train Accuracy: 0.8571\n",
            "Epoch 338/500, Loss: 0.3297, Train Accuracy: 0.8571\n",
            "Epoch 339/500, Loss: 0.3276, Train Accuracy: 0.8571\n",
            "Epoch 340/500, Loss: 0.3271, Train Accuracy: 0.8571\n",
            "Epoch 341/500, Loss: 0.3277, Train Accuracy: 0.8571\n",
            "Epoch 342/500, Loss: 0.3279, Train Accuracy: 0.8571\n",
            "Epoch 343/500, Loss: 0.3267, Train Accuracy: 0.8571\n",
            "Epoch 344/500, Loss: 0.3260, Train Accuracy: 0.8714\n",
            "Epoch 345/500, Loss: 0.3260, Train Accuracy: 0.8571\n",
            "Epoch 346/500, Loss: 0.3259, Train Accuracy: 0.8714\n",
            "Epoch 347/500, Loss: 0.3257, Train Accuracy: 0.8571\n",
            "Epoch 348/500, Loss: 0.3264, Train Accuracy: 0.9000\n",
            "Epoch 349/500, Loss: 0.3276, Train Accuracy: 0.8714\n",
            "Epoch 350/500, Loss: 0.3292, Train Accuracy: 0.9000\n",
            "Epoch 351/500, Loss: 0.3287, Train Accuracy: 0.8714\n",
            "Epoch 352/500, Loss: 0.3253, Train Accuracy: 0.8714\n",
            "Epoch 353/500, Loss: 0.3213, Train Accuracy: 0.8571\n",
            "Epoch 354/500, Loss: 0.3190, Train Accuracy: 0.8571\n",
            "Epoch 355/500, Loss: 0.3177, Train Accuracy: 0.8429\n",
            "Epoch 356/500, Loss: 0.3169, Train Accuracy: 0.8571\n",
            "Epoch 357/500, Loss: 0.3164, Train Accuracy: 0.8571\n",
            "Epoch 358/500, Loss: 0.3166, Train Accuracy: 0.8571\n",
            "Epoch 359/500, Loss: 0.3174, Train Accuracy: 0.9000\n",
            "Epoch 360/500, Loss: 0.3199, Train Accuracy: 0.8429\n",
            "Epoch 361/500, Loss: 0.3268, Train Accuracy: 0.8714\n",
            "Epoch 362/500, Loss: 0.3409, Train Accuracy: 0.7857\n",
            "Epoch 363/500, Loss: 0.3601, Train Accuracy: 0.8857\n",
            "Epoch 364/500, Loss: 0.3619, Train Accuracy: 0.8000\n",
            "Epoch 365/500, Loss: 0.3387, Train Accuracy: 0.8714\n",
            "Epoch 366/500, Loss: 0.3145, Train Accuracy: 0.8857\n",
            "Epoch 367/500, Loss: 0.3248, Train Accuracy: 0.7857\n",
            "Epoch 368/500, Loss: 0.3431, Train Accuracy: 0.8857\n",
            "Epoch 369/500, Loss: 0.3381, Train Accuracy: 0.8571\n",
            "Epoch 370/500, Loss: 0.3200, Train Accuracy: 0.8571\n",
            "Epoch 371/500, Loss: 0.3087, Train Accuracy: 0.9000\n",
            "Epoch 372/500, Loss: 0.3141, Train Accuracy: 0.8429\n",
            "Epoch 373/500, Loss: 0.3222, Train Accuracy: 0.9000\n",
            "Epoch 374/500, Loss: 0.3181, Train Accuracy: 0.8571\n",
            "Epoch 375/500, Loss: 0.3084, Train Accuracy: 0.8571\n",
            "Epoch 376/500, Loss: 0.3066, Train Accuracy: 0.9000\n",
            "Epoch 377/500, Loss: 0.3122, Train Accuracy: 0.8571\n",
            "Epoch 378/500, Loss: 0.3150, Train Accuracy: 0.9000\n",
            "Epoch 379/500, Loss: 0.3121, Train Accuracy: 0.8571\n",
            "Epoch 380/500, Loss: 0.3066, Train Accuracy: 0.8714\n",
            "Epoch 381/500, Loss: 0.3033, Train Accuracy: 0.8714\n",
            "Epoch 382/500, Loss: 0.3028, Train Accuracy: 0.8714\n",
            "Epoch 383/500, Loss: 0.3053, Train Accuracy: 0.9000\n",
            "Epoch 384/500, Loss: 0.3076, Train Accuracy: 0.8714\n",
            "Epoch 385/500, Loss: 0.3057, Train Accuracy: 0.9000\n",
            "Epoch 386/500, Loss: 0.3023, Train Accuracy: 0.8571\n",
            "Epoch 387/500, Loss: 0.2999, Train Accuracy: 0.8714\n",
            "Epoch 388/500, Loss: 0.2988, Train Accuracy: 0.8714\n",
            "Epoch 389/500, Loss: 0.2986, Train Accuracy: 0.8571\n",
            "Epoch 390/500, Loss: 0.2986, Train Accuracy: 0.8857\n",
            "Epoch 391/500, Loss: 0.2995, Train Accuracy: 0.8714\n",
            "Epoch 392/500, Loss: 0.3008, Train Accuracy: 0.9000\n",
            "Epoch 393/500, Loss: 0.3021, Train Accuracy: 0.8714\n",
            "Epoch 394/500, Loss: 0.3024, Train Accuracy: 0.9000\n",
            "Epoch 395/500, Loss: 0.3005, Train Accuracy: 0.8714\n",
            "Epoch 396/500, Loss: 0.2978, Train Accuracy: 0.8857\n",
            "Epoch 397/500, Loss: 0.2949, Train Accuracy: 0.8714\n",
            "Epoch 398/500, Loss: 0.2929, Train Accuracy: 0.8714\n",
            "Epoch 399/500, Loss: 0.2925, Train Accuracy: 0.8857\n",
            "Epoch 400/500, Loss: 0.2929, Train Accuracy: 0.8714\n",
            "Epoch 401/500, Loss: 0.2946, Train Accuracy: 0.9000\n",
            "Epoch 402/500, Loss: 0.2992, Train Accuracy: 0.8571\n",
            "Epoch 403/500, Loss: 0.3073, Train Accuracy: 0.8714\n",
            "Epoch 404/500, Loss: 0.3158, Train Accuracy: 0.8143\n",
            "Epoch 405/500, Loss: 0.3123, Train Accuracy: 0.9000\n",
            "Epoch 406/500, Loss: 0.2981, Train Accuracy: 0.8714\n",
            "Epoch 407/500, Loss: 0.2889, Train Accuracy: 0.8714\n",
            "Epoch 408/500, Loss: 0.2912, Train Accuracy: 0.9000\n",
            "Epoch 409/500, Loss: 0.3035, Train Accuracy: 0.8429\n",
            "Epoch 410/500, Loss: 0.3235, Train Accuracy: 0.8714\n",
            "Epoch 411/500, Loss: 0.3407, Train Accuracy: 0.8143\n",
            "Epoch 412/500, Loss: 0.3360, Train Accuracy: 0.8857\n",
            "Epoch 413/500, Loss: 0.3014, Train Accuracy: 0.9000\n",
            "Epoch 414/500, Loss: 0.2942, Train Accuracy: 0.8143\n",
            "Epoch 415/500, Loss: 0.3199, Train Accuracy: 0.8714\n",
            "Epoch 416/500, Loss: 0.3141, Train Accuracy: 0.8857\n",
            "Epoch 417/500, Loss: 0.2878, Train Accuracy: 0.8857\n",
            "Epoch 418/500, Loss: 0.2897, Train Accuracy: 0.9000\n",
            "Epoch 419/500, Loss: 0.3077, Train Accuracy: 0.8571\n",
            "Epoch 420/500, Loss: 0.3030, Train Accuracy: 0.9000\n",
            "Epoch 421/500, Loss: 0.2863, Train Accuracy: 0.9000\n",
            "Epoch 422/500, Loss: 0.2837, Train Accuracy: 0.8571\n",
            "Epoch 423/500, Loss: 0.2973, Train Accuracy: 0.9000\n",
            "Epoch 424/500, Loss: 0.3002, Train Accuracy: 0.8714\n",
            "Epoch 425/500, Loss: 0.2854, Train Accuracy: 0.9143\n",
            "Epoch 426/500, Loss: 0.2789, Train Accuracy: 0.9000\n",
            "Epoch 427/500, Loss: 0.2879, Train Accuracy: 0.8714\n",
            "Epoch 428/500, Loss: 0.2910, Train Accuracy: 0.9000\n",
            "Epoch 429/500, Loss: 0.2829, Train Accuracy: 0.8857\n",
            "Epoch 430/500, Loss: 0.2764, Train Accuracy: 0.8857\n",
            "Epoch 431/500, Loss: 0.2819, Train Accuracy: 0.9000\n",
            "Epoch 432/500, Loss: 0.2889, Train Accuracy: 0.8714\n",
            "Epoch 433/500, Loss: 0.2837, Train Accuracy: 0.8857\n",
            "Epoch 434/500, Loss: 0.2751, Train Accuracy: 0.8857\n",
            "Epoch 435/500, Loss: 0.2744, Train Accuracy: 0.8857\n",
            "Epoch 436/500, Loss: 0.2798, Train Accuracy: 0.9000\n",
            "Epoch 437/500, Loss: 0.2825, Train Accuracy: 0.8857\n",
            "Epoch 438/500, Loss: 0.2767, Train Accuracy: 0.8857\n",
            "Epoch 439/500, Loss: 0.2717, Train Accuracy: 0.8857\n",
            "Epoch 440/500, Loss: 0.2710, Train Accuracy: 0.9000\n",
            "Epoch 441/500, Loss: 0.2736, Train Accuracy: 0.9000\n",
            "Epoch 442/500, Loss: 0.2753, Train Accuracy: 0.8857\n",
            "Epoch 443/500, Loss: 0.2735, Train Accuracy: 0.8857\n",
            "Epoch 444/500, Loss: 0.2702, Train Accuracy: 0.9000\n",
            "Epoch 445/500, Loss: 0.2676, Train Accuracy: 0.9000\n",
            "Epoch 446/500, Loss: 0.2673, Train Accuracy: 0.8857\n",
            "Epoch 447/500, Loss: 0.2687, Train Accuracy: 0.9000\n",
            "Epoch 448/500, Loss: 0.2695, Train Accuracy: 0.9000\n",
            "Epoch 449/500, Loss: 0.2703, Train Accuracy: 0.8857\n",
            "Epoch 450/500, Loss: 0.2699, Train Accuracy: 0.9000\n",
            "Epoch 451/500, Loss: 0.2691, Train Accuracy: 0.9000\n",
            "Epoch 452/500, Loss: 0.2676, Train Accuracy: 0.9000\n",
            "Epoch 453/500, Loss: 0.2660, Train Accuracy: 0.9143\n",
            "Epoch 454/500, Loss: 0.2636, Train Accuracy: 0.9000\n",
            "Epoch 455/500, Loss: 0.2619, Train Accuracy: 0.9000\n",
            "Epoch 456/500, Loss: 0.2608, Train Accuracy: 0.9000\n",
            "Epoch 457/500, Loss: 0.2604, Train Accuracy: 0.9000\n",
            "Epoch 458/500, Loss: 0.2606, Train Accuracy: 0.9143\n",
            "Epoch 459/500, Loss: 0.2616, Train Accuracy: 0.9000\n",
            "Epoch 460/500, Loss: 0.2642, Train Accuracy: 0.9143\n",
            "Epoch 461/500, Loss: 0.2678, Train Accuracy: 0.9000\n",
            "Epoch 462/500, Loss: 0.2738, Train Accuracy: 0.8857\n",
            "Epoch 463/500, Loss: 0.2774, Train Accuracy: 0.9000\n",
            "Epoch 464/500, Loss: 0.2790, Train Accuracy: 0.8857\n",
            "Epoch 465/500, Loss: 0.2714, Train Accuracy: 0.9000\n",
            "Epoch 466/500, Loss: 0.2606, Train Accuracy: 0.9000\n",
            "Epoch 467/500, Loss: 0.2550, Train Accuracy: 0.9286\n",
            "Epoch 468/500, Loss: 0.2584, Train Accuracy: 0.9000\n",
            "Epoch 469/500, Loss: 0.2655, Train Accuracy: 0.8857\n",
            "Epoch 470/500, Loss: 0.2723, Train Accuracy: 0.9000\n",
            "Epoch 471/500, Loss: 0.2777, Train Accuracy: 0.9000\n",
            "Epoch 472/500, Loss: 0.2719, Train Accuracy: 0.9000\n",
            "Epoch 473/500, Loss: 0.2616, Train Accuracy: 0.9000\n",
            "Epoch 474/500, Loss: 0.2518, Train Accuracy: 0.9286\n",
            "Epoch 475/500, Loss: 0.2526, Train Accuracy: 0.9000\n",
            "Epoch 476/500, Loss: 0.2611, Train Accuracy: 0.8857\n",
            "Epoch 477/500, Loss: 0.2692, Train Accuracy: 0.9000\n",
            "Epoch 478/500, Loss: 0.2727, Train Accuracy: 0.9000\n",
            "Epoch 479/500, Loss: 0.2635, Train Accuracy: 0.9143\n",
            "Epoch 480/500, Loss: 0.2528, Train Accuracy: 0.9000\n",
            "Epoch 481/500, Loss: 0.2469, Train Accuracy: 0.9429\n",
            "Epoch 482/500, Loss: 0.2526, Train Accuracy: 0.9000\n",
            "Epoch 483/500, Loss: 0.2647, Train Accuracy: 0.8714\n",
            "Epoch 484/500, Loss: 0.2769, Train Accuracy: 0.8857\n",
            "Epoch 485/500, Loss: 0.2826, Train Accuracy: 0.8857\n",
            "Epoch 486/500, Loss: 0.2655, Train Accuracy: 0.9143\n",
            "Epoch 487/500, Loss: 0.2475, Train Accuracy: 0.9143\n",
            "Epoch 488/500, Loss: 0.2483, Train Accuracy: 0.9143\n",
            "Epoch 489/500, Loss: 0.2616, Train Accuracy: 0.9000\n",
            "Epoch 490/500, Loss: 0.2687, Train Accuracy: 0.9000\n",
            "Epoch 491/500, Loss: 0.2604, Train Accuracy: 0.9143\n",
            "Epoch 492/500, Loss: 0.2469, Train Accuracy: 0.9000\n",
            "Epoch 493/500, Loss: 0.2420, Train Accuracy: 0.9143\n",
            "Epoch 494/500, Loss: 0.2476, Train Accuracy: 0.9000\n",
            "Epoch 495/500, Loss: 0.2544, Train Accuracy: 0.9286\n",
            "Epoch 496/500, Loss: 0.2533, Train Accuracy: 0.9000\n",
            "Epoch 497/500, Loss: 0.2486, Train Accuracy: 0.9429\n",
            "Epoch 498/500, Loss: 0.2420, Train Accuracy: 0.9000\n",
            "Epoch 499/500, Loss: 0.2379, Train Accuracy: 0.9000\n",
            "Epoch 500/500, Loss: 0.2383, Train Accuracy: 0.9286\n",
            "Final Test Accuracy: 0.7333\n"
          ]
        }
      ]
    }
  ]
}